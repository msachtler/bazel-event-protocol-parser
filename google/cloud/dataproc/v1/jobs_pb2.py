# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/cloud/dataproc/v1/jobs.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='google/cloud/dataproc/v1/jobs.proto',
  package='google.cloud.dataproc.v1',
  syntax='proto3',
  serialized_pb=_b('\n#google/cloud/dataproc/v1/jobs.proto\x12\x18google.cloud.dataproc.v1\x1a\x1cgoogle/api/annotations.proto\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1fgoogle/protobuf/timestamp.proto\"\xc1\x02\n\rLoggingConfig\x12W\n\x11\x64river_log_levels\x18\x02 \x03(\x0b\x32<.google.cloud.dataproc.v1.LoggingConfig.DriverLogLevelsEntry\x1a\x65\n\x14\x44riverLogLevelsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12<\n\x05value\x18\x02 \x01(\x0e\x32-.google.cloud.dataproc.v1.LoggingConfig.Level:\x02\x38\x01\"p\n\x05Level\x12\x15\n\x11LEVEL_UNSPECIFIED\x10\x00\x12\x07\n\x03\x41LL\x10\x01\x12\t\n\x05TRACE\x10\x02\x12\t\n\x05\x44\x45\x42UG\x10\x03\x12\x08\n\x04INFO\x10\x04\x12\x08\n\x04WARN\x10\x05\x12\t\n\x05\x45RROR\x10\x06\x12\t\n\x05\x46\x41TAL\x10\x07\x12\x07\n\x03OFF\x10\x08\"\xd3\x02\n\tHadoopJob\x12\x1b\n\x11main_jar_file_uri\x18\x01 \x01(\tH\x00\x12\x14\n\nmain_class\x18\x02 \x01(\tH\x00\x12\x0c\n\x04\x61rgs\x18\x03 \x03(\t\x12\x15\n\rjar_file_uris\x18\x04 \x03(\t\x12\x11\n\tfile_uris\x18\x05 \x03(\t\x12\x14\n\x0c\x61rchive_uris\x18\x06 \x03(\t\x12G\n\nproperties\x18\x07 \x03(\x0b\x32\x33.google.cloud.dataproc.v1.HadoopJob.PropertiesEntry\x12?\n\x0elogging_config\x18\x08 \x01(\x0b\x32\'.google.cloud.dataproc.v1.LoggingConfig\x1a\x31\n\x0fPropertiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\x08\n\x06\x64river\"\xd1\x02\n\x08SparkJob\x12\x1b\n\x11main_jar_file_uri\x18\x01 \x01(\tH\x00\x12\x14\n\nmain_class\x18\x02 \x01(\tH\x00\x12\x0c\n\x04\x61rgs\x18\x03 \x03(\t\x12\x15\n\rjar_file_uris\x18\x04 \x03(\t\x12\x11\n\tfile_uris\x18\x05 \x03(\t\x12\x14\n\x0c\x61rchive_uris\x18\x06 \x03(\t\x12\x46\n\nproperties\x18\x07 \x03(\x0b\x32\x32.google.cloud.dataproc.v1.SparkJob.PropertiesEntry\x12?\n\x0elogging_config\x18\x08 \x01(\x0b\x32\'.google.cloud.dataproc.v1.LoggingConfig\x1a\x31\n\x0fPropertiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\x08\n\x06\x64river\"\xd0\x02\n\nPySparkJob\x12\x1c\n\x14main_python_file_uri\x18\x01 \x01(\t\x12\x0c\n\x04\x61rgs\x18\x02 \x03(\t\x12\x18\n\x10python_file_uris\x18\x03 \x03(\t\x12\x15\n\rjar_file_uris\x18\x04 \x03(\t\x12\x11\n\tfile_uris\x18\x05 \x03(\t\x12\x14\n\x0c\x61rchive_uris\x18\x06 \x03(\t\x12H\n\nproperties\x18\x07 \x03(\x0b\x32\x34.google.cloud.dataproc.v1.PySparkJob.PropertiesEntry\x12?\n\x0elogging_config\x18\x08 \x01(\x0b\x32\'.google.cloud.dataproc.v1.LoggingConfig\x1a\x31\n\x0fPropertiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x1c\n\tQueryList\x12\x0f\n\x07queries\x18\x01 \x03(\t\"\xa1\x03\n\x07HiveJob\x12\x18\n\x0equery_file_uri\x18\x01 \x01(\tH\x00\x12\x39\n\nquery_list\x18\x02 \x01(\x0b\x32#.google.cloud.dataproc.v1.QueryListH\x00\x12\x1b\n\x13\x63ontinue_on_failure\x18\x03 \x01(\x08\x12P\n\x10script_variables\x18\x04 \x03(\x0b\x32\x36.google.cloud.dataproc.v1.HiveJob.ScriptVariablesEntry\x12\x45\n\nproperties\x18\x05 \x03(\x0b\x32\x31.google.cloud.dataproc.v1.HiveJob.PropertiesEntry\x12\x15\n\rjar_file_uris\x18\x06 \x03(\t\x1a\x36\n\x14ScriptVariablesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x31\n\x0fPropertiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\t\n\x07queries\"\xd1\x03\n\x0bSparkSqlJob\x12\x18\n\x0equery_file_uri\x18\x01 \x01(\tH\x00\x12\x39\n\nquery_list\x18\x02 \x01(\x0b\x32#.google.cloud.dataproc.v1.QueryListH\x00\x12T\n\x10script_variables\x18\x03 \x03(\x0b\x32:.google.cloud.dataproc.v1.SparkSqlJob.ScriptVariablesEntry\x12I\n\nproperties\x18\x04 \x03(\x0b\x32\x35.google.cloud.dataproc.v1.SparkSqlJob.PropertiesEntry\x12\x15\n\rjar_file_uris\x18\x38 \x03(\t\x12?\n\x0elogging_config\x18\x06 \x01(\x0b\x32\'.google.cloud.dataproc.v1.LoggingConfig\x1a\x36\n\x14ScriptVariablesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x31\n\x0fPropertiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\t\n\x07queries\"\xdf\x03\n\x06PigJob\x12\x18\n\x0equery_file_uri\x18\x01 \x01(\tH\x00\x12\x39\n\nquery_list\x18\x02 \x01(\x0b\x32#.google.cloud.dataproc.v1.QueryListH\x00\x12\x1b\n\x13\x63ontinue_on_failure\x18\x03 \x01(\x08\x12O\n\x10script_variables\x18\x04 \x03(\x0b\x32\x35.google.cloud.dataproc.v1.PigJob.ScriptVariablesEntry\x12\x44\n\nproperties\x18\x05 \x03(\x0b\x32\x30.google.cloud.dataproc.v1.PigJob.PropertiesEntry\x12\x15\n\rjar_file_uris\x18\x06 \x03(\t\x12?\n\x0elogging_config\x18\x07 \x01(\x0b\x32\'.google.cloud.dataproc.v1.LoggingConfig\x1a\x36\n\x14ScriptVariablesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x31\n\x0fPropertiesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x42\t\n\x07queries\":\n\x0cJobPlacement\x12\x14\n\x0c\x63luster_name\x18\x01 \x01(\t\x12\x14\n\x0c\x63luster_uuid\x18\x02 \x01(\t\"\xa3\x02\n\tJobStatus\x12\x38\n\x05state\x18\x01 \x01(\x0e\x32).google.cloud.dataproc.v1.JobStatus.State\x12\x0f\n\x07\x64\x65tails\x18\x02 \x01(\t\x12\x34\n\x10state_start_time\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"\x94\x01\n\x05State\x12\x15\n\x11STATE_UNSPECIFIED\x10\x00\x12\x0b\n\x07PENDING\x10\x01\x12\x0e\n\nSETUP_DONE\x10\x08\x12\x0b\n\x07RUNNING\x10\x02\x12\x12\n\x0e\x43\x41NCEL_PENDING\x10\x03\x12\x12\n\x0e\x43\x41NCEL_STARTED\x10\x07\x12\r\n\tCANCELLED\x10\x04\x12\x08\n\x04\x44ONE\x10\x05\x12\t\n\x05\x45RROR\x10\x06\"2\n\x0cJobReference\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\"\x9c\x05\n\x03Job\x12\x39\n\treference\x18\x01 \x01(\x0b\x32&.google.cloud.dataproc.v1.JobReference\x12\x39\n\tplacement\x18\x02 \x01(\x0b\x32&.google.cloud.dataproc.v1.JobPlacement\x12\x39\n\nhadoop_job\x18\x03 \x01(\x0b\x32#.google.cloud.dataproc.v1.HadoopJobH\x00\x12\x37\n\tspark_job\x18\x04 \x01(\x0b\x32\".google.cloud.dataproc.v1.SparkJobH\x00\x12;\n\x0bpyspark_job\x18\x05 \x01(\x0b\x32$.google.cloud.dataproc.v1.PySparkJobH\x00\x12\x35\n\x08hive_job\x18\x06 \x01(\x0b\x32!.google.cloud.dataproc.v1.HiveJobH\x00\x12\x33\n\x07pig_job\x18\x07 \x01(\x0b\x32 .google.cloud.dataproc.v1.PigJobH\x00\x12>\n\rspark_sql_job\x18\x0c \x01(\x0b\x32%.google.cloud.dataproc.v1.SparkSqlJobH\x00\x12\x33\n\x06status\x18\x08 \x01(\x0b\x32#.google.cloud.dataproc.v1.JobStatus\x12;\n\x0estatus_history\x18\r \x03(\x0b\x32#.google.cloud.dataproc.v1.JobStatus\x12\"\n\x1a\x64river_output_resource_uri\x18\x11 \x01(\t\x12 \n\x18\x64river_control_files_uri\x18\x0f \x01(\tB\n\n\x08type_job\"b\n\x10SubmitJobRequest\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x0e\n\x06region\x18\x03 \x01(\t\x12*\n\x03job\x18\x02 \x01(\x0b\x32\x1d.google.cloud.dataproc.v1.Job\"C\n\rGetJobRequest\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x0e\n\x06region\x18\x03 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\"\x80\x02\n\x0fListJobsRequest\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x0e\n\x06region\x18\x06 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x12\n\npage_token\x18\x03 \x01(\t\x12\x14\n\x0c\x63luster_name\x18\x04 \x01(\t\x12T\n\x11job_state_matcher\x18\x05 \x01(\x0e\x32\x39.google.cloud.dataproc.v1.ListJobsRequest.JobStateMatcher\"6\n\x0fJobStateMatcher\x12\x07\n\x03\x41LL\x10\x00\x12\n\n\x06\x41\x43TIVE\x10\x01\x12\x0e\n\nNON_ACTIVE\x10\x02\"X\n\x10ListJobsResponse\x12+\n\x04jobs\x18\x01 \x03(\x0b\x32\x1d.google.cloud.dataproc.v1.Job\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\"F\n\x10\x43\x61ncelJobRequest\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x0e\n\x06region\x18\x03 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\"F\n\x10\x44\x65leteJobRequest\x12\x12\n\nproject_id\x18\x01 \x01(\t\x12\x0e\n\x06region\x18\x03 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t2\x96\x06\n\rJobController\x12\x99\x01\n\tSubmitJob\x12*.google.cloud.dataproc.v1.SubmitJobRequest\x1a\x1d.google.cloud.dataproc.v1.Job\"A\x82\xd3\xe4\x93\x02;\"6/v1/projects/{project_id}/regions/{region}/jobs:submit:\x01*\x12\x92\x01\n\x06GetJob\x12\'.google.cloud.dataproc.v1.GetJobRequest\x1a\x1d.google.cloud.dataproc.v1.Job\"@\x82\xd3\xe4\x93\x02:\x12\x38/v1/projects/{project_id}/regions/{region}/jobs/{job_id}\x12\x9a\x01\n\x08ListJobs\x12).google.cloud.dataproc.v1.ListJobsRequest\x1a*.google.cloud.dataproc.v1.ListJobsResponse\"7\x82\xd3\xe4\x93\x02\x31\x12//v1/projects/{project_id}/regions/{region}/jobs\x12\xa2\x01\n\tCancelJob\x12*.google.cloud.dataproc.v1.CancelJobRequest\x1a\x1d.google.cloud.dataproc.v1.Job\"J\x82\xd3\xe4\x93\x02\x44\"?/v1/projects/{project_id}/regions/{region}/jobs/{job_id}:cancel:\x01*\x12\x91\x01\n\tDeleteJob\x12*.google.cloud.dataproc.v1.DeleteJobRequest\x1a\x16.google.protobuf.Empty\"@\x82\xd3\xe4\x93\x02:*8/v1/projects/{project_id}/regions/{region}/jobs/{job_id}Bm\n\x1c\x63om.google.cloud.dataproc.v1B\tJobsProtoP\x01Z@google.golang.org/genproto/googleapis/cloud/dataproc/v1;dataprocb\x06proto3')
  ,
  dependencies=[google_dot_api_dot_annotations__pb2.DESCRIPTOR,google_dot_protobuf_dot_empty__pb2.DESCRIPTOR,google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR,])



_LOGGINGCONFIG_LEVEL = _descriptor.EnumDescriptor(
  name='Level',
  full_name='google.cloud.dataproc.v1.LoggingConfig.Level',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='LEVEL_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='ALL', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='TRACE', index=2, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='DEBUG', index=3, number=3,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='INFO', index=4, number=4,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='WARN', index=5, number=5,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='ERROR', index=6, number=6,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='FATAL', index=7, number=7,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='OFF', index=8, number=8,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=367,
  serialized_end=479,
)
_sym_db.RegisterEnumDescriptor(_LOGGINGCONFIG_LEVEL)

_JOBSTATUS_STATE = _descriptor.EnumDescriptor(
  name='State',
  full_name='google.cloud.dataproc.v1.JobStatus.State',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='STATE_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='PENDING', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='SETUP_DONE', index=2, number=8,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='RUNNING', index=3, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='CANCEL_PENDING', index=4, number=3,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='CANCEL_STARTED', index=5, number=7,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='CANCELLED', index=6, number=4,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='DONE', index=7, number=5,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='ERROR', index=8, number=6,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=3106,
  serialized_end=3254,
)
_sym_db.RegisterEnumDescriptor(_JOBSTATUS_STATE)

_LISTJOBSREQUEST_JOBSTATEMATCHER = _descriptor.EnumDescriptor(
  name='JobStateMatcher',
  full_name='google.cloud.dataproc.v1.ListJobsRequest.JobStateMatcher',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ALL', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='ACTIVE', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='NON_ACTIVE', index=2, number=2,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=4351,
  serialized_end=4405,
)
_sym_db.RegisterEnumDescriptor(_LISTJOBSREQUEST_JOBSTATEMATCHER)


_LOGGINGCONFIG_DRIVERLOGLEVELSENTRY = _descriptor.Descriptor(
  name='DriverLogLevelsEntry',
  full_name='google.cloud.dataproc.v1.LoggingConfig.DriverLogLevelsEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.LoggingConfig.DriverLogLevelsEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.LoggingConfig.DriverLogLevelsEntry.value', index=1,
      number=2, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=264,
  serialized_end=365,
)

_LOGGINGCONFIG = _descriptor.Descriptor(
  name='LoggingConfig',
  full_name='google.cloud.dataproc.v1.LoggingConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='driver_log_levels', full_name='google.cloud.dataproc.v1.LoggingConfig.driver_log_levels', index=0,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_LOGGINGCONFIG_DRIVERLOGLEVELSENTRY, ],
  enum_types=[
    _LOGGINGCONFIG_LEVEL,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=158,
  serialized_end=479,
)


_HADOOPJOB_PROPERTIESENTRY = _descriptor.Descriptor(
  name='PropertiesEntry',
  full_name='google.cloud.dataproc.v1.HadoopJob.PropertiesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.HadoopJob.PropertiesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.HadoopJob.PropertiesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=762,
  serialized_end=811,
)

_HADOOPJOB = _descriptor.Descriptor(
  name='HadoopJob',
  full_name='google.cloud.dataproc.v1.HadoopJob',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='main_jar_file_uri', full_name='google.cloud.dataproc.v1.HadoopJob.main_jar_file_uri', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='main_class', full_name='google.cloud.dataproc.v1.HadoopJob.main_class', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='args', full_name='google.cloud.dataproc.v1.HadoopJob.args', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='jar_file_uris', full_name='google.cloud.dataproc.v1.HadoopJob.jar_file_uris', index=3,
      number=4, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='file_uris', full_name='google.cloud.dataproc.v1.HadoopJob.file_uris', index=4,
      number=5, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='archive_uris', full_name='google.cloud.dataproc.v1.HadoopJob.archive_uris', index=5,
      number=6, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='properties', full_name='google.cloud.dataproc.v1.HadoopJob.properties', index=6,
      number=7, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='logging_config', full_name='google.cloud.dataproc.v1.HadoopJob.logging_config', index=7,
      number=8, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_HADOOPJOB_PROPERTIESENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='driver', full_name='google.cloud.dataproc.v1.HadoopJob.driver',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=482,
  serialized_end=821,
)


_SPARKJOB_PROPERTIESENTRY = _descriptor.Descriptor(
  name='PropertiesEntry',
  full_name='google.cloud.dataproc.v1.SparkJob.PropertiesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.SparkJob.PropertiesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.SparkJob.PropertiesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=762,
  serialized_end=811,
)

_SPARKJOB = _descriptor.Descriptor(
  name='SparkJob',
  full_name='google.cloud.dataproc.v1.SparkJob',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='main_jar_file_uri', full_name='google.cloud.dataproc.v1.SparkJob.main_jar_file_uri', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='main_class', full_name='google.cloud.dataproc.v1.SparkJob.main_class', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='args', full_name='google.cloud.dataproc.v1.SparkJob.args', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='jar_file_uris', full_name='google.cloud.dataproc.v1.SparkJob.jar_file_uris', index=3,
      number=4, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='file_uris', full_name='google.cloud.dataproc.v1.SparkJob.file_uris', index=4,
      number=5, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='archive_uris', full_name='google.cloud.dataproc.v1.SparkJob.archive_uris', index=5,
      number=6, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='properties', full_name='google.cloud.dataproc.v1.SparkJob.properties', index=6,
      number=7, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='logging_config', full_name='google.cloud.dataproc.v1.SparkJob.logging_config', index=7,
      number=8, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_SPARKJOB_PROPERTIESENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='driver', full_name='google.cloud.dataproc.v1.SparkJob.driver',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=824,
  serialized_end=1161,
)


_PYSPARKJOB_PROPERTIESENTRY = _descriptor.Descriptor(
  name='PropertiesEntry',
  full_name='google.cloud.dataproc.v1.PySparkJob.PropertiesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.PySparkJob.PropertiesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.PySparkJob.PropertiesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=762,
  serialized_end=811,
)

_PYSPARKJOB = _descriptor.Descriptor(
  name='PySparkJob',
  full_name='google.cloud.dataproc.v1.PySparkJob',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='main_python_file_uri', full_name='google.cloud.dataproc.v1.PySparkJob.main_python_file_uri', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='args', full_name='google.cloud.dataproc.v1.PySparkJob.args', index=1,
      number=2, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='python_file_uris', full_name='google.cloud.dataproc.v1.PySparkJob.python_file_uris', index=2,
      number=3, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='jar_file_uris', full_name='google.cloud.dataproc.v1.PySparkJob.jar_file_uris', index=3,
      number=4, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='file_uris', full_name='google.cloud.dataproc.v1.PySparkJob.file_uris', index=4,
      number=5, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='archive_uris', full_name='google.cloud.dataproc.v1.PySparkJob.archive_uris', index=5,
      number=6, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='properties', full_name='google.cloud.dataproc.v1.PySparkJob.properties', index=6,
      number=7, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='logging_config', full_name='google.cloud.dataproc.v1.PySparkJob.logging_config', index=7,
      number=8, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_PYSPARKJOB_PROPERTIESENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1164,
  serialized_end=1500,
)


_QUERYLIST = _descriptor.Descriptor(
  name='QueryList',
  full_name='google.cloud.dataproc.v1.QueryList',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='queries', full_name='google.cloud.dataproc.v1.QueryList.queries', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1502,
  serialized_end=1530,
)


_HIVEJOB_SCRIPTVARIABLESENTRY = _descriptor.Descriptor(
  name='ScriptVariablesEntry',
  full_name='google.cloud.dataproc.v1.HiveJob.ScriptVariablesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.HiveJob.ScriptVariablesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.HiveJob.ScriptVariablesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1834,
  serialized_end=1888,
)

_HIVEJOB_PROPERTIESENTRY = _descriptor.Descriptor(
  name='PropertiesEntry',
  full_name='google.cloud.dataproc.v1.HiveJob.PropertiesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.HiveJob.PropertiesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.HiveJob.PropertiesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=762,
  serialized_end=811,
)

_HIVEJOB = _descriptor.Descriptor(
  name='HiveJob',
  full_name='google.cloud.dataproc.v1.HiveJob',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='query_file_uri', full_name='google.cloud.dataproc.v1.HiveJob.query_file_uri', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='query_list', full_name='google.cloud.dataproc.v1.HiveJob.query_list', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='continue_on_failure', full_name='google.cloud.dataproc.v1.HiveJob.continue_on_failure', index=2,
      number=3, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='script_variables', full_name='google.cloud.dataproc.v1.HiveJob.script_variables', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='properties', full_name='google.cloud.dataproc.v1.HiveJob.properties', index=4,
      number=5, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='jar_file_uris', full_name='google.cloud.dataproc.v1.HiveJob.jar_file_uris', index=5,
      number=6, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_HIVEJOB_SCRIPTVARIABLESENTRY, _HIVEJOB_PROPERTIESENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='queries', full_name='google.cloud.dataproc.v1.HiveJob.queries',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1533,
  serialized_end=1950,
)


_SPARKSQLJOB_SCRIPTVARIABLESENTRY = _descriptor.Descriptor(
  name='ScriptVariablesEntry',
  full_name='google.cloud.dataproc.v1.SparkSqlJob.ScriptVariablesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.SparkSqlJob.ScriptVariablesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.SparkSqlJob.ScriptVariablesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1834,
  serialized_end=1888,
)

_SPARKSQLJOB_PROPERTIESENTRY = _descriptor.Descriptor(
  name='PropertiesEntry',
  full_name='google.cloud.dataproc.v1.SparkSqlJob.PropertiesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.SparkSqlJob.PropertiesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.SparkSqlJob.PropertiesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=762,
  serialized_end=811,
)

_SPARKSQLJOB = _descriptor.Descriptor(
  name='SparkSqlJob',
  full_name='google.cloud.dataproc.v1.SparkSqlJob',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='query_file_uri', full_name='google.cloud.dataproc.v1.SparkSqlJob.query_file_uri', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='query_list', full_name='google.cloud.dataproc.v1.SparkSqlJob.query_list', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='script_variables', full_name='google.cloud.dataproc.v1.SparkSqlJob.script_variables', index=2,
      number=3, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='properties', full_name='google.cloud.dataproc.v1.SparkSqlJob.properties', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='jar_file_uris', full_name='google.cloud.dataproc.v1.SparkSqlJob.jar_file_uris', index=4,
      number=56, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='logging_config', full_name='google.cloud.dataproc.v1.SparkSqlJob.logging_config', index=5,
      number=6, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_SPARKSQLJOB_SCRIPTVARIABLESENTRY, _SPARKSQLJOB_PROPERTIESENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='queries', full_name='google.cloud.dataproc.v1.SparkSqlJob.queries',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1953,
  serialized_end=2418,
)


_PIGJOB_SCRIPTVARIABLESENTRY = _descriptor.Descriptor(
  name='ScriptVariablesEntry',
  full_name='google.cloud.dataproc.v1.PigJob.ScriptVariablesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.PigJob.ScriptVariablesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.PigJob.ScriptVariablesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1834,
  serialized_end=1888,
)

_PIGJOB_PROPERTIESENTRY = _descriptor.Descriptor(
  name='PropertiesEntry',
  full_name='google.cloud.dataproc.v1.PigJob.PropertiesEntry',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='key', full_name='google.cloud.dataproc.v1.PigJob.PropertiesEntry.key', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='value', full_name='google.cloud.dataproc.v1.PigJob.PropertiesEntry.value', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=762,
  serialized_end=811,
)

_PIGJOB = _descriptor.Descriptor(
  name='PigJob',
  full_name='google.cloud.dataproc.v1.PigJob',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='query_file_uri', full_name='google.cloud.dataproc.v1.PigJob.query_file_uri', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='query_list', full_name='google.cloud.dataproc.v1.PigJob.query_list', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='continue_on_failure', full_name='google.cloud.dataproc.v1.PigJob.continue_on_failure', index=2,
      number=3, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='script_variables', full_name='google.cloud.dataproc.v1.PigJob.script_variables', index=3,
      number=4, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='properties', full_name='google.cloud.dataproc.v1.PigJob.properties', index=4,
      number=5, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='jar_file_uris', full_name='google.cloud.dataproc.v1.PigJob.jar_file_uris', index=5,
      number=6, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='logging_config', full_name='google.cloud.dataproc.v1.PigJob.logging_config', index=6,
      number=7, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[_PIGJOB_SCRIPTVARIABLESENTRY, _PIGJOB_PROPERTIESENTRY, ],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='queries', full_name='google.cloud.dataproc.v1.PigJob.queries',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=2421,
  serialized_end=2900,
)


_JOBPLACEMENT = _descriptor.Descriptor(
  name='JobPlacement',
  full_name='google.cloud.dataproc.v1.JobPlacement',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='cluster_name', full_name='google.cloud.dataproc.v1.JobPlacement.cluster_name', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='cluster_uuid', full_name='google.cloud.dataproc.v1.JobPlacement.cluster_uuid', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2902,
  serialized_end=2960,
)


_JOBSTATUS = _descriptor.Descriptor(
  name='JobStatus',
  full_name='google.cloud.dataproc.v1.JobStatus',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='state', full_name='google.cloud.dataproc.v1.JobStatus.state', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='details', full_name='google.cloud.dataproc.v1.JobStatus.details', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='state_start_time', full_name='google.cloud.dataproc.v1.JobStatus.state_start_time', index=2,
      number=6, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _JOBSTATUS_STATE,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2963,
  serialized_end=3254,
)


_JOBREFERENCE = _descriptor.Descriptor(
  name='JobReference',
  full_name='google.cloud.dataproc.v1.JobReference',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='google.cloud.dataproc.v1.JobReference.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='job_id', full_name='google.cloud.dataproc.v1.JobReference.job_id', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=3256,
  serialized_end=3306,
)


_JOB = _descriptor.Descriptor(
  name='Job',
  full_name='google.cloud.dataproc.v1.Job',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='reference', full_name='google.cloud.dataproc.v1.Job.reference', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='placement', full_name='google.cloud.dataproc.v1.Job.placement', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='hadoop_job', full_name='google.cloud.dataproc.v1.Job.hadoop_job', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='spark_job', full_name='google.cloud.dataproc.v1.Job.spark_job', index=3,
      number=4, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='pyspark_job', full_name='google.cloud.dataproc.v1.Job.pyspark_job', index=4,
      number=5, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='hive_job', full_name='google.cloud.dataproc.v1.Job.hive_job', index=5,
      number=6, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='pig_job', full_name='google.cloud.dataproc.v1.Job.pig_job', index=6,
      number=7, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='spark_sql_job', full_name='google.cloud.dataproc.v1.Job.spark_sql_job', index=7,
      number=12, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='status', full_name='google.cloud.dataproc.v1.Job.status', index=8,
      number=8, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='status_history', full_name='google.cloud.dataproc.v1.Job.status_history', index=9,
      number=13, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='driver_output_resource_uri', full_name='google.cloud.dataproc.v1.Job.driver_output_resource_uri', index=10,
      number=17, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='driver_control_files_uri', full_name='google.cloud.dataproc.v1.Job.driver_control_files_uri', index=11,
      number=15, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='type_job', full_name='google.cloud.dataproc.v1.Job.type_job',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=3309,
  serialized_end=3977,
)


_SUBMITJOBREQUEST = _descriptor.Descriptor(
  name='SubmitJobRequest',
  full_name='google.cloud.dataproc.v1.SubmitJobRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='google.cloud.dataproc.v1.SubmitJobRequest.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='region', full_name='google.cloud.dataproc.v1.SubmitJobRequest.region', index=1,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='job', full_name='google.cloud.dataproc.v1.SubmitJobRequest.job', index=2,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=3979,
  serialized_end=4077,
)


_GETJOBREQUEST = _descriptor.Descriptor(
  name='GetJobRequest',
  full_name='google.cloud.dataproc.v1.GetJobRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='google.cloud.dataproc.v1.GetJobRequest.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='region', full_name='google.cloud.dataproc.v1.GetJobRequest.region', index=1,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='job_id', full_name='google.cloud.dataproc.v1.GetJobRequest.job_id', index=2,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=4079,
  serialized_end=4146,
)


_LISTJOBSREQUEST = _descriptor.Descriptor(
  name='ListJobsRequest',
  full_name='google.cloud.dataproc.v1.ListJobsRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='google.cloud.dataproc.v1.ListJobsRequest.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='region', full_name='google.cloud.dataproc.v1.ListJobsRequest.region', index=1,
      number=6, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='page_size', full_name='google.cloud.dataproc.v1.ListJobsRequest.page_size', index=2,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='page_token', full_name='google.cloud.dataproc.v1.ListJobsRequest.page_token', index=3,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='cluster_name', full_name='google.cloud.dataproc.v1.ListJobsRequest.cluster_name', index=4,
      number=4, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='job_state_matcher', full_name='google.cloud.dataproc.v1.ListJobsRequest.job_state_matcher', index=5,
      number=5, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _LISTJOBSREQUEST_JOBSTATEMATCHER,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=4149,
  serialized_end=4405,
)


_LISTJOBSRESPONSE = _descriptor.Descriptor(
  name='ListJobsResponse',
  full_name='google.cloud.dataproc.v1.ListJobsResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='jobs', full_name='google.cloud.dataproc.v1.ListJobsResponse.jobs', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='next_page_token', full_name='google.cloud.dataproc.v1.ListJobsResponse.next_page_token', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=4407,
  serialized_end=4495,
)


_CANCELJOBREQUEST = _descriptor.Descriptor(
  name='CancelJobRequest',
  full_name='google.cloud.dataproc.v1.CancelJobRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='google.cloud.dataproc.v1.CancelJobRequest.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='region', full_name='google.cloud.dataproc.v1.CancelJobRequest.region', index=1,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='job_id', full_name='google.cloud.dataproc.v1.CancelJobRequest.job_id', index=2,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=4497,
  serialized_end=4567,
)


_DELETEJOBREQUEST = _descriptor.Descriptor(
  name='DeleteJobRequest',
  full_name='google.cloud.dataproc.v1.DeleteJobRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='project_id', full_name='google.cloud.dataproc.v1.DeleteJobRequest.project_id', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='region', full_name='google.cloud.dataproc.v1.DeleteJobRequest.region', index=1,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='job_id', full_name='google.cloud.dataproc.v1.DeleteJobRequest.job_id', index=2,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=4569,
  serialized_end=4639,
)

_LOGGINGCONFIG_DRIVERLOGLEVELSENTRY.fields_by_name['value'].enum_type = _LOGGINGCONFIG_LEVEL
_LOGGINGCONFIG_DRIVERLOGLEVELSENTRY.containing_type = _LOGGINGCONFIG
_LOGGINGCONFIG.fields_by_name['driver_log_levels'].message_type = _LOGGINGCONFIG_DRIVERLOGLEVELSENTRY
_LOGGINGCONFIG_LEVEL.containing_type = _LOGGINGCONFIG
_HADOOPJOB_PROPERTIESENTRY.containing_type = _HADOOPJOB
_HADOOPJOB.fields_by_name['properties'].message_type = _HADOOPJOB_PROPERTIESENTRY
_HADOOPJOB.fields_by_name['logging_config'].message_type = _LOGGINGCONFIG
_HADOOPJOB.oneofs_by_name['driver'].fields.append(
  _HADOOPJOB.fields_by_name['main_jar_file_uri'])
_HADOOPJOB.fields_by_name['main_jar_file_uri'].containing_oneof = _HADOOPJOB.oneofs_by_name['driver']
_HADOOPJOB.oneofs_by_name['driver'].fields.append(
  _HADOOPJOB.fields_by_name['main_class'])
_HADOOPJOB.fields_by_name['main_class'].containing_oneof = _HADOOPJOB.oneofs_by_name['driver']
_SPARKJOB_PROPERTIESENTRY.containing_type = _SPARKJOB
_SPARKJOB.fields_by_name['properties'].message_type = _SPARKJOB_PROPERTIESENTRY
_SPARKJOB.fields_by_name['logging_config'].message_type = _LOGGINGCONFIG
_SPARKJOB.oneofs_by_name['driver'].fields.append(
  _SPARKJOB.fields_by_name['main_jar_file_uri'])
_SPARKJOB.fields_by_name['main_jar_file_uri'].containing_oneof = _SPARKJOB.oneofs_by_name['driver']
_SPARKJOB.oneofs_by_name['driver'].fields.append(
  _SPARKJOB.fields_by_name['main_class'])
_SPARKJOB.fields_by_name['main_class'].containing_oneof = _SPARKJOB.oneofs_by_name['driver']
_PYSPARKJOB_PROPERTIESENTRY.containing_type = _PYSPARKJOB
_PYSPARKJOB.fields_by_name['properties'].message_type = _PYSPARKJOB_PROPERTIESENTRY
_PYSPARKJOB.fields_by_name['logging_config'].message_type = _LOGGINGCONFIG
_HIVEJOB_SCRIPTVARIABLESENTRY.containing_type = _HIVEJOB
_HIVEJOB_PROPERTIESENTRY.containing_type = _HIVEJOB
_HIVEJOB.fields_by_name['query_list'].message_type = _QUERYLIST
_HIVEJOB.fields_by_name['script_variables'].message_type = _HIVEJOB_SCRIPTVARIABLESENTRY
_HIVEJOB.fields_by_name['properties'].message_type = _HIVEJOB_PROPERTIESENTRY
_HIVEJOB.oneofs_by_name['queries'].fields.append(
  _HIVEJOB.fields_by_name['query_file_uri'])
_HIVEJOB.fields_by_name['query_file_uri'].containing_oneof = _HIVEJOB.oneofs_by_name['queries']
_HIVEJOB.oneofs_by_name['queries'].fields.append(
  _HIVEJOB.fields_by_name['query_list'])
_HIVEJOB.fields_by_name['query_list'].containing_oneof = _HIVEJOB.oneofs_by_name['queries']
_SPARKSQLJOB_SCRIPTVARIABLESENTRY.containing_type = _SPARKSQLJOB
_SPARKSQLJOB_PROPERTIESENTRY.containing_type = _SPARKSQLJOB
_SPARKSQLJOB.fields_by_name['query_list'].message_type = _QUERYLIST
_SPARKSQLJOB.fields_by_name['script_variables'].message_type = _SPARKSQLJOB_SCRIPTVARIABLESENTRY
_SPARKSQLJOB.fields_by_name['properties'].message_type = _SPARKSQLJOB_PROPERTIESENTRY
_SPARKSQLJOB.fields_by_name['logging_config'].message_type = _LOGGINGCONFIG
_SPARKSQLJOB.oneofs_by_name['queries'].fields.append(
  _SPARKSQLJOB.fields_by_name['query_file_uri'])
_SPARKSQLJOB.fields_by_name['query_file_uri'].containing_oneof = _SPARKSQLJOB.oneofs_by_name['queries']
_SPARKSQLJOB.oneofs_by_name['queries'].fields.append(
  _SPARKSQLJOB.fields_by_name['query_list'])
_SPARKSQLJOB.fields_by_name['query_list'].containing_oneof = _SPARKSQLJOB.oneofs_by_name['queries']
_PIGJOB_SCRIPTVARIABLESENTRY.containing_type = _PIGJOB
_PIGJOB_PROPERTIESENTRY.containing_type = _PIGJOB
_PIGJOB.fields_by_name['query_list'].message_type = _QUERYLIST
_PIGJOB.fields_by_name['script_variables'].message_type = _PIGJOB_SCRIPTVARIABLESENTRY
_PIGJOB.fields_by_name['properties'].message_type = _PIGJOB_PROPERTIESENTRY
_PIGJOB.fields_by_name['logging_config'].message_type = _LOGGINGCONFIG
_PIGJOB.oneofs_by_name['queries'].fields.append(
  _PIGJOB.fields_by_name['query_file_uri'])
_PIGJOB.fields_by_name['query_file_uri'].containing_oneof = _PIGJOB.oneofs_by_name['queries']
_PIGJOB.oneofs_by_name['queries'].fields.append(
  _PIGJOB.fields_by_name['query_list'])
_PIGJOB.fields_by_name['query_list'].containing_oneof = _PIGJOB.oneofs_by_name['queries']
_JOBSTATUS.fields_by_name['state'].enum_type = _JOBSTATUS_STATE
_JOBSTATUS.fields_by_name['state_start_time'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP
_JOBSTATUS_STATE.containing_type = _JOBSTATUS
_JOB.fields_by_name['reference'].message_type = _JOBREFERENCE
_JOB.fields_by_name['placement'].message_type = _JOBPLACEMENT
_JOB.fields_by_name['hadoop_job'].message_type = _HADOOPJOB
_JOB.fields_by_name['spark_job'].message_type = _SPARKJOB
_JOB.fields_by_name['pyspark_job'].message_type = _PYSPARKJOB
_JOB.fields_by_name['hive_job'].message_type = _HIVEJOB
_JOB.fields_by_name['pig_job'].message_type = _PIGJOB
_JOB.fields_by_name['spark_sql_job'].message_type = _SPARKSQLJOB
_JOB.fields_by_name['status'].message_type = _JOBSTATUS
_JOB.fields_by_name['status_history'].message_type = _JOBSTATUS
_JOB.oneofs_by_name['type_job'].fields.append(
  _JOB.fields_by_name['hadoop_job'])
_JOB.fields_by_name['hadoop_job'].containing_oneof = _JOB.oneofs_by_name['type_job']
_JOB.oneofs_by_name['type_job'].fields.append(
  _JOB.fields_by_name['spark_job'])
_JOB.fields_by_name['spark_job'].containing_oneof = _JOB.oneofs_by_name['type_job']
_JOB.oneofs_by_name['type_job'].fields.append(
  _JOB.fields_by_name['pyspark_job'])
_JOB.fields_by_name['pyspark_job'].containing_oneof = _JOB.oneofs_by_name['type_job']
_JOB.oneofs_by_name['type_job'].fields.append(
  _JOB.fields_by_name['hive_job'])
_JOB.fields_by_name['hive_job'].containing_oneof = _JOB.oneofs_by_name['type_job']
_JOB.oneofs_by_name['type_job'].fields.append(
  _JOB.fields_by_name['pig_job'])
_JOB.fields_by_name['pig_job'].containing_oneof = _JOB.oneofs_by_name['type_job']
_JOB.oneofs_by_name['type_job'].fields.append(
  _JOB.fields_by_name['spark_sql_job'])
_JOB.fields_by_name['spark_sql_job'].containing_oneof = _JOB.oneofs_by_name['type_job']
_SUBMITJOBREQUEST.fields_by_name['job'].message_type = _JOB
_LISTJOBSREQUEST.fields_by_name['job_state_matcher'].enum_type = _LISTJOBSREQUEST_JOBSTATEMATCHER
_LISTJOBSREQUEST_JOBSTATEMATCHER.containing_type = _LISTJOBSREQUEST
_LISTJOBSRESPONSE.fields_by_name['jobs'].message_type = _JOB
DESCRIPTOR.message_types_by_name['LoggingConfig'] = _LOGGINGCONFIG
DESCRIPTOR.message_types_by_name['HadoopJob'] = _HADOOPJOB
DESCRIPTOR.message_types_by_name['SparkJob'] = _SPARKJOB
DESCRIPTOR.message_types_by_name['PySparkJob'] = _PYSPARKJOB
DESCRIPTOR.message_types_by_name['QueryList'] = _QUERYLIST
DESCRIPTOR.message_types_by_name['HiveJob'] = _HIVEJOB
DESCRIPTOR.message_types_by_name['SparkSqlJob'] = _SPARKSQLJOB
DESCRIPTOR.message_types_by_name['PigJob'] = _PIGJOB
DESCRIPTOR.message_types_by_name['JobPlacement'] = _JOBPLACEMENT
DESCRIPTOR.message_types_by_name['JobStatus'] = _JOBSTATUS
DESCRIPTOR.message_types_by_name['JobReference'] = _JOBREFERENCE
DESCRIPTOR.message_types_by_name['Job'] = _JOB
DESCRIPTOR.message_types_by_name['SubmitJobRequest'] = _SUBMITJOBREQUEST
DESCRIPTOR.message_types_by_name['GetJobRequest'] = _GETJOBREQUEST
DESCRIPTOR.message_types_by_name['ListJobsRequest'] = _LISTJOBSREQUEST
DESCRIPTOR.message_types_by_name['ListJobsResponse'] = _LISTJOBSRESPONSE
DESCRIPTOR.message_types_by_name['CancelJobRequest'] = _CANCELJOBREQUEST
DESCRIPTOR.message_types_by_name['DeleteJobRequest'] = _DELETEJOBREQUEST
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

LoggingConfig = _reflection.GeneratedProtocolMessageType('LoggingConfig', (_message.Message,), dict(

  DriverLogLevelsEntry = _reflection.GeneratedProtocolMessageType('DriverLogLevelsEntry', (_message.Message,), dict(
    DESCRIPTOR = _LOGGINGCONFIG_DRIVERLOGLEVELSENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.LoggingConfig.DriverLogLevelsEntry)
    ))
  ,
  DESCRIPTOR = _LOGGINGCONFIG,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.LoggingConfig)
  ))
_sym_db.RegisterMessage(LoggingConfig)
_sym_db.RegisterMessage(LoggingConfig.DriverLogLevelsEntry)

HadoopJob = _reflection.GeneratedProtocolMessageType('HadoopJob', (_message.Message,), dict(

  PropertiesEntry = _reflection.GeneratedProtocolMessageType('PropertiesEntry', (_message.Message,), dict(
    DESCRIPTOR = _HADOOPJOB_PROPERTIESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.HadoopJob.PropertiesEntry)
    ))
  ,
  DESCRIPTOR = _HADOOPJOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.HadoopJob)
  ))
_sym_db.RegisterMessage(HadoopJob)
_sym_db.RegisterMessage(HadoopJob.PropertiesEntry)

SparkJob = _reflection.GeneratedProtocolMessageType('SparkJob', (_message.Message,), dict(

  PropertiesEntry = _reflection.GeneratedProtocolMessageType('PropertiesEntry', (_message.Message,), dict(
    DESCRIPTOR = _SPARKJOB_PROPERTIESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.SparkJob.PropertiesEntry)
    ))
  ,
  DESCRIPTOR = _SPARKJOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.SparkJob)
  ))
_sym_db.RegisterMessage(SparkJob)
_sym_db.RegisterMessage(SparkJob.PropertiesEntry)

PySparkJob = _reflection.GeneratedProtocolMessageType('PySparkJob', (_message.Message,), dict(

  PropertiesEntry = _reflection.GeneratedProtocolMessageType('PropertiesEntry', (_message.Message,), dict(
    DESCRIPTOR = _PYSPARKJOB_PROPERTIESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.PySparkJob.PropertiesEntry)
    ))
  ,
  DESCRIPTOR = _PYSPARKJOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.PySparkJob)
  ))
_sym_db.RegisterMessage(PySparkJob)
_sym_db.RegisterMessage(PySparkJob.PropertiesEntry)

QueryList = _reflection.GeneratedProtocolMessageType('QueryList', (_message.Message,), dict(
  DESCRIPTOR = _QUERYLIST,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.QueryList)
  ))
_sym_db.RegisterMessage(QueryList)

HiveJob = _reflection.GeneratedProtocolMessageType('HiveJob', (_message.Message,), dict(

  ScriptVariablesEntry = _reflection.GeneratedProtocolMessageType('ScriptVariablesEntry', (_message.Message,), dict(
    DESCRIPTOR = _HIVEJOB_SCRIPTVARIABLESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.HiveJob.ScriptVariablesEntry)
    ))
  ,

  PropertiesEntry = _reflection.GeneratedProtocolMessageType('PropertiesEntry', (_message.Message,), dict(
    DESCRIPTOR = _HIVEJOB_PROPERTIESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.HiveJob.PropertiesEntry)
    ))
  ,
  DESCRIPTOR = _HIVEJOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.HiveJob)
  ))
_sym_db.RegisterMessage(HiveJob)
_sym_db.RegisterMessage(HiveJob.ScriptVariablesEntry)
_sym_db.RegisterMessage(HiveJob.PropertiesEntry)

SparkSqlJob = _reflection.GeneratedProtocolMessageType('SparkSqlJob', (_message.Message,), dict(

  ScriptVariablesEntry = _reflection.GeneratedProtocolMessageType('ScriptVariablesEntry', (_message.Message,), dict(
    DESCRIPTOR = _SPARKSQLJOB_SCRIPTVARIABLESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.SparkSqlJob.ScriptVariablesEntry)
    ))
  ,

  PropertiesEntry = _reflection.GeneratedProtocolMessageType('PropertiesEntry', (_message.Message,), dict(
    DESCRIPTOR = _SPARKSQLJOB_PROPERTIESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.SparkSqlJob.PropertiesEntry)
    ))
  ,
  DESCRIPTOR = _SPARKSQLJOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.SparkSqlJob)
  ))
_sym_db.RegisterMessage(SparkSqlJob)
_sym_db.RegisterMessage(SparkSqlJob.ScriptVariablesEntry)
_sym_db.RegisterMessage(SparkSqlJob.PropertiesEntry)

PigJob = _reflection.GeneratedProtocolMessageType('PigJob', (_message.Message,), dict(

  ScriptVariablesEntry = _reflection.GeneratedProtocolMessageType('ScriptVariablesEntry', (_message.Message,), dict(
    DESCRIPTOR = _PIGJOB_SCRIPTVARIABLESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.PigJob.ScriptVariablesEntry)
    ))
  ,

  PropertiesEntry = _reflection.GeneratedProtocolMessageType('PropertiesEntry', (_message.Message,), dict(
    DESCRIPTOR = _PIGJOB_PROPERTIESENTRY,
    __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
    # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.PigJob.PropertiesEntry)
    ))
  ,
  DESCRIPTOR = _PIGJOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.PigJob)
  ))
_sym_db.RegisterMessage(PigJob)
_sym_db.RegisterMessage(PigJob.ScriptVariablesEntry)
_sym_db.RegisterMessage(PigJob.PropertiesEntry)

JobPlacement = _reflection.GeneratedProtocolMessageType('JobPlacement', (_message.Message,), dict(
  DESCRIPTOR = _JOBPLACEMENT,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.JobPlacement)
  ))
_sym_db.RegisterMessage(JobPlacement)

JobStatus = _reflection.GeneratedProtocolMessageType('JobStatus', (_message.Message,), dict(
  DESCRIPTOR = _JOBSTATUS,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.JobStatus)
  ))
_sym_db.RegisterMessage(JobStatus)

JobReference = _reflection.GeneratedProtocolMessageType('JobReference', (_message.Message,), dict(
  DESCRIPTOR = _JOBREFERENCE,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.JobReference)
  ))
_sym_db.RegisterMessage(JobReference)

Job = _reflection.GeneratedProtocolMessageType('Job', (_message.Message,), dict(
  DESCRIPTOR = _JOB,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.Job)
  ))
_sym_db.RegisterMessage(Job)

SubmitJobRequest = _reflection.GeneratedProtocolMessageType('SubmitJobRequest', (_message.Message,), dict(
  DESCRIPTOR = _SUBMITJOBREQUEST,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.SubmitJobRequest)
  ))
_sym_db.RegisterMessage(SubmitJobRequest)

GetJobRequest = _reflection.GeneratedProtocolMessageType('GetJobRequest', (_message.Message,), dict(
  DESCRIPTOR = _GETJOBREQUEST,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.GetJobRequest)
  ))
_sym_db.RegisterMessage(GetJobRequest)

ListJobsRequest = _reflection.GeneratedProtocolMessageType('ListJobsRequest', (_message.Message,), dict(
  DESCRIPTOR = _LISTJOBSREQUEST,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.ListJobsRequest)
  ))
_sym_db.RegisterMessage(ListJobsRequest)

ListJobsResponse = _reflection.GeneratedProtocolMessageType('ListJobsResponse', (_message.Message,), dict(
  DESCRIPTOR = _LISTJOBSRESPONSE,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.ListJobsResponse)
  ))
_sym_db.RegisterMessage(ListJobsResponse)

CancelJobRequest = _reflection.GeneratedProtocolMessageType('CancelJobRequest', (_message.Message,), dict(
  DESCRIPTOR = _CANCELJOBREQUEST,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.CancelJobRequest)
  ))
_sym_db.RegisterMessage(CancelJobRequest)

DeleteJobRequest = _reflection.GeneratedProtocolMessageType('DeleteJobRequest', (_message.Message,), dict(
  DESCRIPTOR = _DELETEJOBREQUEST,
  __module__ = 'google.cloud.dataproc.v1.jobs_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1.DeleteJobRequest)
  ))
_sym_db.RegisterMessage(DeleteJobRequest)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n\034com.google.cloud.dataproc.v1B\tJobsProtoP\001Z@google.golang.org/genproto/googleapis/cloud/dataproc/v1;dataproc'))
_LOGGINGCONFIG_DRIVERLOGLEVELSENTRY.has_options = True
_LOGGINGCONFIG_DRIVERLOGLEVELSENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_HADOOPJOB_PROPERTIESENTRY.has_options = True
_HADOOPJOB_PROPERTIESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_SPARKJOB_PROPERTIESENTRY.has_options = True
_SPARKJOB_PROPERTIESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_PYSPARKJOB_PROPERTIESENTRY.has_options = True
_PYSPARKJOB_PROPERTIESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_HIVEJOB_SCRIPTVARIABLESENTRY.has_options = True
_HIVEJOB_SCRIPTVARIABLESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_HIVEJOB_PROPERTIESENTRY.has_options = True
_HIVEJOB_PROPERTIESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_SPARKSQLJOB_SCRIPTVARIABLESENTRY.has_options = True
_SPARKSQLJOB_SCRIPTVARIABLESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_SPARKSQLJOB_PROPERTIESENTRY.has_options = True
_SPARKSQLJOB_PROPERTIESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_PIGJOB_SCRIPTVARIABLESENTRY.has_options = True
_PIGJOB_SCRIPTVARIABLESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
_PIGJOB_PROPERTIESENTRY.has_options = True
_PIGJOB_PROPERTIESENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
try:
  # THESE ELEMENTS WILL BE DEPRECATED.
  # Please use the generated *_pb2_grpc.py files instead.
  import grpc
  from grpc.beta import implementations as beta_implementations
  from grpc.beta import interfaces as beta_interfaces
  from grpc.framework.common import cardinality
  from grpc.framework.interfaces.face import utilities as face_utilities


  class JobControllerStub(object):
    """The JobController provides methods to manage jobs.
    """

    def __init__(self, channel):
      """Constructor.

      Args:
        channel: A grpc.Channel.
      """
      self.SubmitJob = channel.unary_unary(
          '/google.cloud.dataproc.v1.JobController/SubmitJob',
          request_serializer=SubmitJobRequest.SerializeToString,
          response_deserializer=Job.FromString,
          )
      self.GetJob = channel.unary_unary(
          '/google.cloud.dataproc.v1.JobController/GetJob',
          request_serializer=GetJobRequest.SerializeToString,
          response_deserializer=Job.FromString,
          )
      self.ListJobs = channel.unary_unary(
          '/google.cloud.dataproc.v1.JobController/ListJobs',
          request_serializer=ListJobsRequest.SerializeToString,
          response_deserializer=ListJobsResponse.FromString,
          )
      self.CancelJob = channel.unary_unary(
          '/google.cloud.dataproc.v1.JobController/CancelJob',
          request_serializer=CancelJobRequest.SerializeToString,
          response_deserializer=Job.FromString,
          )
      self.DeleteJob = channel.unary_unary(
          '/google.cloud.dataproc.v1.JobController/DeleteJob',
          request_serializer=DeleteJobRequest.SerializeToString,
          response_deserializer=google_dot_protobuf_dot_empty__pb2.Empty.FromString,
          )


  class JobControllerServicer(object):
    """The JobController provides methods to manage jobs.
    """

    def SubmitJob(self, request, context):
      """Submits a job to a cluster.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def GetJob(self, request, context):
      """Gets the resource representation for a job in a project.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def ListJobs(self, request, context):
      """Lists regions/{region}/jobs in a project.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def CancelJob(self, request, context):
      """Starts a job cancellation request. To access the job resource
      after cancellation, call
      [regions/{region}/jobs.list](/dataproc/reference/rest/v1/projects.regions.jobs/list) or
      [regions/{region}/jobs.get](/dataproc/reference/rest/v1/projects.regions.jobs/get).
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def DeleteJob(self, request, context):
      """Deletes the job from the project. If the job is active, the delete fails,
      and the response returns `FAILED_PRECONDITION`.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')


  def add_JobControllerServicer_to_server(servicer, server):
    rpc_method_handlers = {
        'SubmitJob': grpc.unary_unary_rpc_method_handler(
            servicer.SubmitJob,
            request_deserializer=SubmitJobRequest.FromString,
            response_serializer=Job.SerializeToString,
        ),
        'GetJob': grpc.unary_unary_rpc_method_handler(
            servicer.GetJob,
            request_deserializer=GetJobRequest.FromString,
            response_serializer=Job.SerializeToString,
        ),
        'ListJobs': grpc.unary_unary_rpc_method_handler(
            servicer.ListJobs,
            request_deserializer=ListJobsRequest.FromString,
            response_serializer=ListJobsResponse.SerializeToString,
        ),
        'CancelJob': grpc.unary_unary_rpc_method_handler(
            servicer.CancelJob,
            request_deserializer=CancelJobRequest.FromString,
            response_serializer=Job.SerializeToString,
        ),
        'DeleteJob': grpc.unary_unary_rpc_method_handler(
            servicer.DeleteJob,
            request_deserializer=DeleteJobRequest.FromString,
            response_serializer=google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
        ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
        'google.cloud.dataproc.v1.JobController', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


  class BetaJobControllerServicer(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """The JobController provides methods to manage jobs.
    """
    def SubmitJob(self, request, context):
      """Submits a job to a cluster.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def GetJob(self, request, context):
      """Gets the resource representation for a job in a project.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def ListJobs(self, request, context):
      """Lists regions/{region}/jobs in a project.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def CancelJob(self, request, context):
      """Starts a job cancellation request. To access the job resource
      after cancellation, call
      [regions/{region}/jobs.list](/dataproc/reference/rest/v1/projects.regions.jobs/list) or
      [regions/{region}/jobs.get](/dataproc/reference/rest/v1/projects.regions.jobs/get).
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def DeleteJob(self, request, context):
      """Deletes the job from the project. If the job is active, the delete fails,
      and the response returns `FAILED_PRECONDITION`.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


  class BetaJobControllerStub(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """The JobController provides methods to manage jobs.
    """
    def SubmitJob(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Submits a job to a cluster.
      """
      raise NotImplementedError()
    SubmitJob.future = None
    def GetJob(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Gets the resource representation for a job in a project.
      """
      raise NotImplementedError()
    GetJob.future = None
    def ListJobs(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Lists regions/{region}/jobs in a project.
      """
      raise NotImplementedError()
    ListJobs.future = None
    def CancelJob(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Starts a job cancellation request. To access the job resource
      after cancellation, call
      [regions/{region}/jobs.list](/dataproc/reference/rest/v1/projects.regions.jobs/list) or
      [regions/{region}/jobs.get](/dataproc/reference/rest/v1/projects.regions.jobs/get).
      """
      raise NotImplementedError()
    CancelJob.future = None
    def DeleteJob(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Deletes the job from the project. If the job is active, the delete fails,
      and the response returns `FAILED_PRECONDITION`.
      """
      raise NotImplementedError()
    DeleteJob.future = None


  def beta_create_JobController_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_deserializers = {
      ('google.cloud.dataproc.v1.JobController', 'CancelJob'): CancelJobRequest.FromString,
      ('google.cloud.dataproc.v1.JobController', 'DeleteJob'): DeleteJobRequest.FromString,
      ('google.cloud.dataproc.v1.JobController', 'GetJob'): GetJobRequest.FromString,
      ('google.cloud.dataproc.v1.JobController', 'ListJobs'): ListJobsRequest.FromString,
      ('google.cloud.dataproc.v1.JobController', 'SubmitJob'): SubmitJobRequest.FromString,
    }
    response_serializers = {
      ('google.cloud.dataproc.v1.JobController', 'CancelJob'): Job.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'DeleteJob'): google_dot_protobuf_dot_empty__pb2.Empty.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'GetJob'): Job.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'ListJobs'): ListJobsResponse.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'SubmitJob'): Job.SerializeToString,
    }
    method_implementations = {
      ('google.cloud.dataproc.v1.JobController', 'CancelJob'): face_utilities.unary_unary_inline(servicer.CancelJob),
      ('google.cloud.dataproc.v1.JobController', 'DeleteJob'): face_utilities.unary_unary_inline(servicer.DeleteJob),
      ('google.cloud.dataproc.v1.JobController', 'GetJob'): face_utilities.unary_unary_inline(servicer.GetJob),
      ('google.cloud.dataproc.v1.JobController', 'ListJobs'): face_utilities.unary_unary_inline(servicer.ListJobs),
      ('google.cloud.dataproc.v1.JobController', 'SubmitJob'): face_utilities.unary_unary_inline(servicer.SubmitJob),
    }
    server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
    return beta_implementations.server(method_implementations, options=server_options)


  def beta_create_JobController_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_serializers = {
      ('google.cloud.dataproc.v1.JobController', 'CancelJob'): CancelJobRequest.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'DeleteJob'): DeleteJobRequest.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'GetJob'): GetJobRequest.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'ListJobs'): ListJobsRequest.SerializeToString,
      ('google.cloud.dataproc.v1.JobController', 'SubmitJob'): SubmitJobRequest.SerializeToString,
    }
    response_deserializers = {
      ('google.cloud.dataproc.v1.JobController', 'CancelJob'): Job.FromString,
      ('google.cloud.dataproc.v1.JobController', 'DeleteJob'): google_dot_protobuf_dot_empty__pb2.Empty.FromString,
      ('google.cloud.dataproc.v1.JobController', 'GetJob'): Job.FromString,
      ('google.cloud.dataproc.v1.JobController', 'ListJobs'): ListJobsResponse.FromString,
      ('google.cloud.dataproc.v1.JobController', 'SubmitJob'): Job.FromString,
    }
    cardinalities = {
      'CancelJob': cardinality.Cardinality.UNARY_UNARY,
      'DeleteJob': cardinality.Cardinality.UNARY_UNARY,
      'GetJob': cardinality.Cardinality.UNARY_UNARY,
      'ListJobs': cardinality.Cardinality.UNARY_UNARY,
      'SubmitJob': cardinality.Cardinality.UNARY_UNARY,
    }
    stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
    return beta_implementations.dynamic_stub(channel, 'google.cloud.dataproc.v1.JobController', cardinalities, options=stub_options)
except ImportError:
  pass
# @@protoc_insertion_point(module_scope)
